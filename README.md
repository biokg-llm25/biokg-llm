# Construction of Biomedical Knowledge Graphs Using Large Language Models
<div align="left">
  <a href="biokg_llm.csv" download>
    <img src="https://img.shields.io/badge/DOWNLOAD%20DATASET-CSV-blue?style=for-the-badge&logo=csv&logoColor=white" alt="Download Dataset CSV">
  </a>
</div>

## TL;DR

We introduce a two-fold contribution:

1️⃣ A **hackable, end-to-end pipeline** that constructs biomedical knowledge graphs from unstructured web data using a **web scraper, fuzzy matching, and large language models (LLMs)**.  
2️⃣ A **curated dataset** generated by applying this method to publicly available **drug leaflets** sourced from online pharmacies — capturing drug-centric attributes often missing in existing biomedical KGs.

**[Download the KG Dataset (CSV)](biokg_llm.csv)** to explore clinically relevant information beyond molecular data.

<img src="figures/Proposed_Pipeline.png" alt="Pipeline Overview" width="1000"/>

## Overview

Knowledge graphs (KGs) are increasingly used to represent biomedical information in structured, interpretable formats. However, existing biomedical KGs often focus narrowly on molecular interactions or adverse events, overlooking the rich, drug-centric data found in package leaflets.

In this work, we present: (1) An end-to-end pipeline for automatically constructing biomedical KGs from unstructured text using an LLM, and (2) A dataset in the form of a knowledge graph, created by applying the proposed method to publicly available drug package inserts sourced from online pharmacy websites.

The proposed method is modular, reproducible, and easy to adapt. Both the LLM and the input data can be substituted to generate different KGs. The resulting KG captures clinically relevant attributes such as side effects, warnings, contraindications, ingredients, dosage guidelines, storage instructions, and physical characteristics, which are often missing in existing medical databases and KGs.

We evaluate the KG through manual inspection and compare its coverage with existing biomedical KGs and databases, highlighting complementary aspects such as storage instructions, dosage guidelines, and ingredient details that are often absent in these resources. We expect this dataset to support future applications in areas such as patient safety and drug recommendation, while the generation method can be easily adopted for other types of unstructured documents.

## Features

- *End-to-End Biomedical KG Pipeline:*  A modular and hackable pipeline that extracts structured knowledge from unstructured text using web scraping, LLMs, NER, and relation mapping. Both the LLM and scraper components can be easily replaced or customized.

- *Drug Leaflet-Centric Knowledge Graph:*  Constructed from 13,000+ drug leaflets sourced from the HPRA, capturing real-world, patient-facing clinical data often overlooked in existing biomedical resources.

- *LLM-Based Information Extraction:*  Utilizes LLaMA 3 70B Instruct for prompt-based extraction of subject–predicate–object triples directly from full-text PDFs, avoiding the need for chunking and preserving context.

- *Ready-to-Use Dataset:*  The resulting knowledge graph can be downloaded [here](https://github.com/biokg-llm25/biokg-llm/blob/main/data/biomedical_kg.csv) in a ready-to-use CSV format.

- *Broader Clinical Coverage:*  Captures practical features often missing in other biomedical KGs and databases, including storage information, physical appearance (shape, color), and inactive ingredients.

- *Generalizable & Open Source:*  The pipeline is reusable and adaptable across domains and document types, and the full codebase is open source.

## Proposed Pipeline

We present an end-to-end pipeline for constructing a biomedical knowledge graph from unstructured drug leaflet data. The process begins with data collection, where drug leaflets are scraped from online pharmacies using a web scraper built using Python and converted into machine-readable text. This raw data is then processed using a prompt-based approach with an LLM for information extraction, focusing on key drug-related entities and their interrelationships. The extracted entities undergo further refinement through NER and relation mapping, ultimately being transformed into nodes and labeled edges. These are subsequently post-processed and organized into a CSV format, which serves as the foundation of the knowledge graph. The figure below provides a visual overview of the entire pipeline, illustrating each processing stage from data collection to knowledge graph construction.

## Installation

Follow these steps to set up the project locally:

### 1. Clone the repository
```bash
git clone https://github.com/biokg-llm25/biokg-llm.git
cd biokg-llm
```

### 2. Create and activate virtual environment
```bash
python3 -m venv env
source env/bin/activate  # On Windows: env\Scripts\activate
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

## Usage
The pipeline is divided into multiple stages for modular processing:

### 1. Data Scraping
- **Step 1: Extract Drug Page URLs**
```bash
python scrape_html_sources.py
```
Scrapes the HPRA website using BeautifulSoup and extracts source code with links to drug leaflet pages. You may replace with a scraper of your choice.
- **Step 2: Download PDFs from Extracted URLs**
```bash
python download_pdfs.py
```
Downloads the actual drug leaflet PDFs based on the extracted page source code.

### 2. Information Extraction Using LLM
- **Step 3: Extract Structured Data from PDFs**
```bash
python extract_information_llm.py
```
Uses a locally hosted LLM (e.g., LLaMA 3 70B Instruct) to extract drug-related information using prompts. Outputs are saved as .txt files in a Q&A format. You may replace the LLM with a model of your choice.


### 3. Knowledge Graph Construction
- **Step 4: Build Initial KG in CSV Format**
```bash
python build_kg_csv.py
```
Parses the extracted .txt file, performs entity recognition and relation mapping, and constructs a raw KG in CSV format.
- **Step 5: Post-Processing & Final KG Generation**
```bash
python postprocess_kg.py
```
Performs post-processing like entity shortening using a locally hosted LLM (LLaMA 3 70B Instruct). You may replace the LLM with a model of your choice.

### 4. Visualization and KG Statistics
```bash
jupyter notebook graph_stats.ipynb
```
Explore key graph statistics of the dataset(as a kG) like:
- Entity & relation type distributions
- Node & edge counts
- Degree distributions and graph connectivity
